---
title: "Cristina Lazcano and Eric Boyd - strawberry endophyte and soil metagenomics 16s/ITS, time course"
author: "Sam Hunter"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, echo=FALSE, results="hide"}

# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("dada2", "biomformat", "phyloseq", "pheatmap", "tidyr")

library('knitr')
knitr::opts_chunk$set(echo = TRUE)

library(dada2); packageVersion("dada2")
library(biomformat); packageVersion("biomformat")
library(phyloseq); packageVersion("phyloseq")
library(ggplot2); packageVersion("ggplot2")
#library(DECIPHER); packageVersion("DECIPHER")
#library(phangorn); packageVersion("phangorn")
library(pheatmap); packageVersion("pheatmap")
library(tidyr)
library(kableExtra)
library(Biostrings)

options(stringsAsFactors=F)

wd = getwd()
knitr::opts_knit$set(root.dir = wd)
setwd(wd)

```

## Reading data etc

```{r setup_filter}

#
path <- "../01-HTS_Preproc/" # CHANGE ME to the directory containing the fastq files after unzipping.
#path <- "../02-Overlap" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)

# Read in "SE" files:
# Note that all of the NTCs were not sequenced.
fnFs.SE = sort(list.files(path, pattern="*_SE.fastq.gz", full.names=T))

#sample.names <- paste("s", sapply(strsplit(basename(fnFs.SE), "_SE"), `[`, 1), sep='')
sample.names <-  sapply(strsplit(basename(fnFs.SE), "_SE"), `[`, 1)

#pdf(file="QC_plots.pdf", w=11, h=8)
# # Examine quality profile plots:
png("fnFs_quality.png", width=2000, height=1000)
plotQualityProfile(fnFs.SE[1:11])
dev.off()

### Note that filtering and trimming should not be necessary if reads are filtered for any
### containing an "N"
#Perform filtering and trimming
#Assign the filenames for the filtered fastq.gz files.
# filt_path <- file.path("01-filtered") # Place filtered files in filtered/ subdirectory
# filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))

#Filter the forward and reverse reads
# out <- filterAndTrim(fwd=fnFs.SE, filt=filtFs, truncLen=0, minLen=350,
#               maxN=0, maxEE=Inf, truncQ=0, rm.phix=F, 
#               trimLeft=0, trimRight=0, minQ=0, rm.lowcomplex=0, orient.fwd = NULL,
#               compress=TRUE, multithread=TRUE, verbose=TRUE)


# This filter is pretty relaxed, we keep almost all reads.  
# out <- as.data.frame(out)
# out$Pct = 100 * out[,"reads.out"]/out[,"reads.in"]
# out

```

```{r errors}
# Learn error rate with forward reads:
errF <- learnErrors(fnFs.SE, multithread=TRUE)

png("errors.png", width=2500, height=1500)
    plotErrors(errF, nominalQ=TRUE)
dev.off()

```

```{r dada2}
dadaUs = dada(fnFs.SE, err=errF, multithread=TRUE, pool=T, OMEGA_C=0)  # OMEGA_C=0 ?
#saveRDS(dadaUs, "dadaUs.RDS")  # This is really large..
gc()
#saveRDS(dadaUs, file="dadaUS.rds") # This file is huge and takes forever to save, don't bother.

```

```{r dada_summaries}
# Construct sequence table:
seqtab <- makeSequenceTable(dadaUs)
rownames(seqtab) = sample.names
save(seqtab, file="seqtab.RData")
dim(seqtab)


# Inspect distribution of sequence lengths:
table(nchar(getSequences(seqtab)))

```
```{r}

seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
save(seqtab.nochim, file="seqtab.nochim.RData")

# Identified 6662 bimeras out of 10874 input sequences.

## TODO: Investigate removeBimeraDenovo further. It seems to be removing a lot of things that are exactly/almost exactly the same
# length as the rest of the amplicons in the study, but that seems surprising given that they are supposedly chimeric sequences.

gc()
dim(seqtab.nochim)
# [1]  213 4212


# What faction of total bases is retained?
sum(seqtab.nochim)/sum(seqtab)
# [1] 0.7666804

# Sequence lengths before nochim:
table(nchar(getSequences(seqtab)))

# 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 
#   5   5   3   2   1   5   4   8   3 113  49  21  10  17  40 251 901 149 192 241 
# 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 
# 174 268 262 396 408 264 177 154 120 133 436 162 182 296 186 404 269 347 168 407 
# 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 
# 160  82 131 150 125  34  28  73  33  19  34  64  49  44  48  23  18 165  42  57 
# 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 
#  32  57  33 103  24  15  18  26  22  23  21  25  32  18  25  23  96  76 140  28 
# 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 
# 442  58  20  16  29  16  11  45   9  11  19  16   9  13   7   8  29  21  12   5 
# 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 
#  47  11  19  31  41  17  19  11  16  17  23  20  25  18  18  18  13  38  19  21 
# 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 
#  18  11  14  16   2  11   5   7   3   8   2   5  10   7   3   7   2   6   7   3 
# 441 442 443 444 445 446 447 448 449 450 452 455 456 458 460 464 465 467 468 473 
#   2   3   5   6   1   1   1   1   1   1   1   1   1   2   1   1   1   1   1   1 
# 474 475 479 480 492 505 507 
#   1   1   1   1   1   1   1 

# Length of sequences discarded by chimera removal:
# nchar(setdiff(getSequences(seqtab),getSequences(seqtab.nochim)))
table(nchar(setdiff(getSequences(seqtab),getSequences(seqtab.nochim))))


# 300 301 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 
#   1   1   2   1   1   1  78  21   4   2   5  22 176 776 101 133 167 110 164 130 
# 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 
# 281 263 171 107  85  65  72 339  98 110 230 137 326 206 286 115 340 117  43  81 
# 343 344 345 346 347 348 349 350 351 352 353 354 355 357 358 359 360 361 362 363 
#  82  75   7  11  41  11   5   7  30   9  12  16   2 114  13  21   8  25   4  34 
# 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 
#   4   1   8   7   3   7   8   3   3   3   4   5  62  48 109  14 282  17   4   3 
# 384 385 386 387 388 390 391 396 397 398 399 400 402 403 404 405 406 407 408 409 
#  13   4   1  24   1   4   1   4   1   2   2  21   6   4   9   3   4   2   3   2 
# 410 411 412 413 414 415 416 417 418 419 421 423 425 433 
#   6   1  12   6   1   1   1  21   2   1   2   2   3   2 


```

```{r PlotChimeraLengthDistribution}

par(mfrow=c(2,1))
barplot(table(nchar(getSequences(seqtab))),  
    main="Sequence length distribution of all ASVs")
barplot(table(nchar(setdiff(getSequences(seqtab),getSequences(seqtab.nochim)))), 
    main="Sequence length distribution of discarded bimeras")


```


```{r}

#Track reads through the pipeline
getN <- function(x) sum(getUniques(x))

track = data.frame(input = sapply(dadaUs, getN),
                   denoised = rowSums(seqtab),
                   nochim = rowSums(seqtab.nochim),
                   ASVs = rowSums(seqtab>0),
                   ASVs.nochim = rowSums(seqtab.nochim>0))

#track <- cbind(out, sapply(dadaUs, getN), rowSums(seqtab), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
#colnames(track) <- c("input", "filtered", "pctfiltered", "denoised", "tabled", "nonchim")
rownames(track) <- sample.names
track

write.table(data.frame(sample=rownames(track), track), file="read_tracking.tsv", sep='\t', row.names=F)
```


```{r heatmap}
pdf(file='ITS_AVS_read_count_heatmap.pdf', width=8, height=16)
df = seqtab.nochim
seqs = colnames(df)
colnames(df) = paste0("ASV", 1:ncol(df))
names(seqs) = colnames(df)
df = df[grep('Blank', rownames(df), invert=T), ]
df = df[grep('blank', rownames(df), invert=T), ]
df = df[grep('Zymo', rownames(df), invert=T), ]
df = df[,order(colSums(df), decreasing=T) ]
pheatmap(log2(df[,1:20]+1), main='Log2 read count for top 20 ASVs from ITS amplicons', cluster_cols=F)
dev.off()
```


```{r UNITE_taxonomy}
# Assign taxonomy to nochim data:
taxa.unite.nochim = assignTaxonomy(seqtab.nochim, "./sh_general_release_04.02.2020/sh_general_release_dynamic_04.02.2020_strawberry.fasta", 
  multithread=T, minBoot=50)
# Species assignment happens on the first pass with ITS?
#taxa.unite.nochim = addSpecies(seqtab.nochim, "./sh_general_release_04.02.2020/sh_general_release_dynamic_04.02.2020.fasta")

save(taxa.unite.nochim, file="taxa.unite.nochim.RData")
gc()
colSums(!is.na(taxa.unite.nochim))

# Without Strawberry ITS sequence
# Kingdom  Phylum   Class   Order  Family   Genus Species 
#    4212    3744    3628    3550    3277    2874    1929 

# With Strawberry ITS sequence
# Kingdom  Phylum   Class   Order  Family   Genus Species
#    4212    3899    3777    3701    3420    3016    2068


# Assign taxonomy to all data:
# taxa.unite.all = assignTaxonomy(seqtab, "./sh_general_release_04.02.2020/sh_general_release_dynamic_04.02.2020.fasta", 
#   multithread = T, minBoot=50)
# #taxa.unite.all = addSpecies(taxa.unite.all, "./sh_general_release_04.02.2020/sh_general_release_dynamic_04.02.2020.fasta")
# save(taxa.unite.all, file="taxa.unite.all.RData")
# gc()
# colSums(!is.na(taxa.unite.all))

# Kingdom  Phylum   Class   Order  Family   Genus Species 
#   10874   10091    9946    9838    9416    8534    5260 


```{r compare_nochim}
# Compare assignments at the Genus level:
library(phyloseq)
ASVs.nochim = DNAStringSet(colnames(seqtab.nochim))
names(ASVs.nochim) = paste0("ASV", 1:ncol(seqtab.nochim))
tmp.seqtab = seqtab.nochim
colnames(tmp.seqtab) = names(ASVs.nochim)
tmp.taxa = taxa.unite.nochim
rownames(tmp.taxa) = names(ASVs.nochim)
ps.nochim = phyloseq(otu_table(tmp.seqtab, taxa_are_rows=FALSE),
             tax_table(tmp.taxa),
             refseq(ASVs.nochim))

ps.nochim.family = tax_glom(ps.nochim, "Family")

# Get total ASVs per Family:
nochim.df = data.frame(Family = tax_table(ps.nochim.family)[,5], ASVcount = colSums(otu_table(ps.nochim.family)))


ASVs.all = DNAStringSet(colnames(seqtab))
names(ASVs.all) = paste0("ASV", 1:ncol(seqtab))
tmp.seqtab = seqtab
colnames(tmp.seqtab) = names(ASVs.all)
tmp.taxa = taxa.unite.all
rownames(tmp.taxa) = names(ASVs.all)
ps.all = phyloseq(otu_table(tmp.seqtab, taxa_are_rows=FALSE),
             tax_table(tmp.taxa),
             refseq(ASVs.all))
ps.all.family = tax_glom(ps.all, "Family")
all.df = data.frame(Family = tax_table(ps.all.family)[,5], ASVcount = colSums(otu_table(ps.all.family)))

# Compare:
all.family = unique(c(nochim.df$Family, all.df$Family))
combined.df = data.frame(Family = all.family, 
                         nochim = nochim.df$ASVcount[match(all.family, nochim.df$Family)],
                         all = all.df$ASVcount[match(all.family, all.df$Family)])

write.table(combined.df, "compare_nochim.tsv", row.names=F, sep='\t')

kable(combined.df) %>%
  kable_styling("striped", full_width = F) %>%
  row_spec(0, angle = 0)

#ps.nochim.genus = tax_glom(ps.nochim, "Genus")

```

```{r rdp_taxonomy}
# Not run:
# taxa.rdp = assignTaxonomy(seqtab, './RDP/rdp_train_set_16.fa.gz', multithread=T)
# taxa.rdp = addSpecies(taxa.rdp, "./RDP/rdp_species_assignment_16.fa.gz")
# gc()
# colSums(!is.na(taxa.rdp))
```

```{r UNITE_taxonomy}

# taxa.UNITE = assignTaxonomy(seqtab.nochim, './UNITE/sh_general_release_dynamic_s_02.02.2019.fasta', multithread = TRUE, tryRC = TRUE)
# gc()
# colSums(!is.na(taxa.UNITE))
# Kingdom  Phylum   Class   Order  Family   Genus Species 
#    1917       2       1       1       1       1       1 

# ---> There are not many/any fungal reads in this dataset.

```


```{r idTaxa}
# TODO check out this idTaxa strategy on the new tutorial:
# https://benjjneb.github.io/dada2/tutorial.html
# Alternatives: The recently developed IdTaxa taxonomic classification method is also available via 
# the DECIPHER Bioconductor package. The paper introducing the IDTAXA algorithm reports classification 
# performance that is better than the long-time standard set by the naive Bayesian classifier. 
# Here we include a code block that allows you to use IdTaxa as a drop-in replacement for assignTaxonomy
# (and it’s faster as well!). Trained classifiers are available from http://DECIPHER.codes/Downloads.html.
# Download the SILVA SSU r132 (modified) file to follow along.

# library(DECIPHER); packageVersion("DECIPHER")

# dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
# load("./IDTAXA/SILVA_SSU_r138_2019.RData") # CHANGE TO THE PATH OF YOUR TRAINING SET
# #ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE, threshold=0) # use all processors
# ids50 <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE, threshold=50) # use all processors
# ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
# # Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
# taxid <- t(sapply(ids50, function(x) {
#         m <- match(ranks, x$rank)
#         taxa <- x$taxon[m]
#         taxa[startsWith(taxa, "unclassified_")] <- NA
#         taxa
# }))
# #colnames(taxid) <- ranks; # c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species")
# # set caps so they match DADA2 
# colnames(taxid) = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species") output 
# rownames(taxid) <- getSequences(seqtab.nochim)
# saveRDS(taxid, file="IDTAXA_taxid.RDS")

# colSums(!is.na(taxid))

#  Domain  Phylum   Class   Order  Family   Genus Species 
#    1941    1695    1630    1500    1249     685       0 


```

```{r Compare_Zymo_Mock}

# zymo.genus = c('Pseudomonas', 'Escherichia/Shigella', 'Salmonella', 'Lactobacillus', 'Enterococcus', 'Staphylococcus', 'Listeria',
#     'Bacillus', 'Saccharomyces', 'Cryptococcus')

# unqs.mock = seqtab.nochim[grep("Zymo", rownames(seqtab.nochim)), ]
# unqs.mock = unqs.mock[,colSums(unqs.mock) > 0]  # drop ASVs with 0 count in mock
# unqs.mock = unqs.mock[,order(colSums(unqs.mock), decreasing=T)]  # order ASVs by count
# mock.countTable = data.frame(taxa.silva.nochim[colnames(unqs.mock), ], stringsAsFactors=F)
# mock.countTable$InZymo =  mock.countTable$Genus %in% zymo.genus
# mock.countTable = data.frame(mock.countTable, t(unqs.mock), stringsAsFactors=F)
# write.table(mock.countTable, file="Mock_count_table.tsv", row.names=F, col.names=T, sep='\t')

# mock.ASVs = DNAStringSet(colnames(unqs.mock))
# names(mock.ASVs) = paste0("ASV.", colSums(unqs.mock), "_", 
# apply(mock.countTable[,c('Class', "Order","Family", "Genus", "Species")], 1, paste, collapse='.'))
# writeXStringSet(mock.ASVs, file="mock_ASVs.fasta", format="fasta")
 
```

```{r countables}

## Create Amplicon Sequence Variant (ASV) table with counts:
CountTable.unite = data.frame(taxa.unite.nochim[colnames(seqtab.nochim), ], t(seqtab.nochim))
CountTable.unite = CountTable.unite[order(rowSums(t(seqtab.nochim)), decreasing=T), ]
write.table(data.frame(Sequence=rownames(CountTable.unite), CountTable.unite), row.names=F, file="AllSamples_AmpliconSequenceVariant_count_UNITE.tsv", sep='\t')

# CountTable.rdp = data.frame(taxa.rdp[colnames(seqtab), ], t(seqtab))
# CountTable.rdp = CountTable.rdp[order(rowSums(t(seqtab)), decreasing=T), ]
# write.table(data.frame(Sequence=rownames(CountTable.rdp), CountTable.rdp), row.names=F, file="AllSamples_AmpliconSequenceVariant_count_RDP.tsv", sep='\t')

```


```{r load_metadata}
# Load metadata for phyloseq object, re-order to match seqtab:
mdata = read.table("../../Master_DNA_SampleList_yr2-Modified.tsv", header=T, as.is=T, sep='\t')
#mdata2 = mdata[match(rownames(seqtab.nochim), mdata$SampleID), ]

### DOUBLE check that there are no missing samples in sample sheet or files:
# [1] "f2rvr2_L1"   <---- IS MISSING!

length(setdiff(rownames(seqtab.nochim), mdata$SampleID)) == 0

# For some reason one sample has a modified name in the ITS set, FIX IT:
rownames(seqtab.nochim)[which(rownames(seqtab.nochim) == 'f2rvr2_L1')] = 'f2rvr2'
save(seqtab.nochim, file="seqtab.nochim.RData")  

### TODO: check that taxa.unite.nochim.RData isn't impacted by this.


mdata2 = mdata[match(rownames(seqtab.nochim), mdata$SampleID), ]
rownames(mdata2) = mdata2$SampleID


kable(mdata2) %>%
  kable_styling("striped", full_width = F) %>%
  row_spec(0, angle = 0)

```

## Make a phylogenetic tree from all of the ASV sequences
```{r maketree}
# https://f1000research.com/articles/5-1492

library("DECIPHER")
library("phangorn")

ASVs.nochim = DNAStringSet(colnames(seqtab.nochim))
names(ASVs.nochim) = paste0("ASV", 1:ncol(seqtab.nochim))

alignment = AlignSeqs(DNAStringSet(ASVs.nochim), anchor=NA, processors=30)

phang.align <- phyDat(as(alignment, "matrix"), type="DNA") # turn into phyDat format
dm <- dist.ml(phang.align) # 
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)  # compute sthe likelihood of a phylogenetic tree given a sequence alignment and a model

## negative edges length changed to 0!
fitGTR <- update(fit, k=4, inv=0.2)
# optim.pml optimizes the different model parameters, this essentially searches for a better tree using a bunch of
# stochasitc rearrangement strategies.
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
#detach("package:phangorn", unload=TRUE)
save(fitGTR, file="fitGTR.RData")
```


```
```{r make_phyloseq_objects}
# Make Phyloseq objects
library(phyloseq)
library(Biostrings)

# load("fitGTR.RData")
# load("seqtab.nochim.RData")
# load('taxa.unite.nochim.RData')

# create a Phyloseq object with UNITE annotation:

ASVs.nochim = DNAStringSet(colnames(seqtab.nochim))
names(ASVs.nochim) = paste0("ASV", 1:ncol(seqtab.nochim))

tmp.seqtab = seqtab.nochim
colnames(tmp.seqtab) = names(ASVs.nochim)
tmp.taxa = taxa.unite.nochim
rownames(tmp.taxa) = names(ASVs.nochim)
ps.unite.nochim = phyloseq(otu_table(tmp.seqtab, taxa_are_rows=FALSE),
             sample_data(mdata2),
             tax_table(tmp.taxa),
             refseq(ASVs.nochim),
             phy_tree(fitGTR$tree))
save(ps.unite.nochim, file="phyloseq_nochim_unite.RData")


``` 

```{r}
# track <- cbind(out, final=rowSums(seqtab[,w]),perc=rowSums(seqtab[,w])/out$reads.in)
# rownames(track) <- sample.names
# write.table(track, file="track.tsv", row.names=F, sep='\t')


kable(track) %>%
  kable_styling("striped", full_width = F) %>%
  row_spec(0, angle = 0)

```
